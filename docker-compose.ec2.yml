# Production Docker Compose Configuration for Single EC2 Instance
# Usage: docker compose -f docker-compose.ec2.yml up -d
#
# This configuration runs all services on a single EC2 instance with:
# - Resource limits to prevent resource exhaustion
# - Production Dockerfiles
# - Health checks for all services
# - Persistent volumes for data
# - Proper restart policies
#
# Before running:
# 1. Set up environment variables in .env file (see infrastructure/ec2/.env.template)
# 2. Ensure all required environment variables are set
# 3. Run database migrations: cd backend && npm run db:migrate:deploy
# 4. Optionally seed reference data: SEED_SCOPE=reference npm run db:seed

services:
  postgres:
    image: postgres:15-alpine
    container_name: isms-postgres-ec2
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-isms_db}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - isms-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ollama:
    image: ollama/ollama:latest
    container_name: isms-ollama-ec2
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - isms-network
    healthcheck:
      test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  document-service:
    build:
      context: ./services/document-service
      dockerfile: Dockerfile
    container_name: isms-document-service-ec2
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=4001
      - INTERNAL_SERVICE_TOKEN=${INTERNAL_SERVICE_TOKEN}
      - CACHE_DIR=/cache
    volumes:
      - document_cache:/cache
    networks:
      - isms-network
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:4001/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ai-service:
    build:
      context: ./services/ai-service
      dockerfile: Dockerfile
    container_name: isms-ai-service-ec2
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=4002
      - INTERNAL_SERVICE_TOKEN=${INTERNAL_SERVICE_TOKEN}
      - OLLAMA_ENDPOINT=http://ollama:11434
      - OLLAMA_MODEL=nomic-embed-text
      - OLLAMA_EMBEDDING_MODEL=nomic-embed-text
    networks:
      - isms-network
    depends_on:
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:4002/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: isms-backend-ec2
    restart: unless-stopped
    ports:
      - "4000:4000"
    volumes:
      # Mount docs directory for ISO 27002 seed script
      - ./docs:/docs:ro
    environment:
      - NODE_ENV=production
      - PORT=4000
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-isms_db}?schema=public
      - SEED_SCOPE=${SEED_SCOPE:-none}
      # Auth configuration
      - AUTH_TENANT_ID=${AUTH_TENANT_ID}
      - AUTH_CLIENT_ID=${AUTH_CLIENT_ID}
      - AUTH_CLIENT_SECRET=${AUTH_CLIENT_SECRET}
      - AUTH_REDIRECT_URI=${AUTH_REDIRECT_URI}
      - AUTH_ALLOWED_EMAIL_DOMAIN=${AUTH_ALLOWED_EMAIL_DOMAIN:-paythru.com}
      # CORS configuration
      - CORS_TRUST_CENTER_ORIGINS=${CORS_TRUST_CENTER_ORIGINS}
      # Trust Centre configuration
      - TRUST_CENTER_JWT_SECRET=${TRUST_CENTER_JWT_SECRET}
      - TRUST_CENTER_JWT_EXPIRY=${TRUST_CENTER_JWT_EXPIRY:-24h}
      - TRUST_CENTER_MAX_FILE_SIZE_MB=${TRUST_CENTER_MAX_FILE_SIZE_MB:-50}
      - TRUST_CENTER_DOWNLOAD_TOKEN_EXPIRY=${TRUST_CENTER_DOWNLOAD_TOKEN_EXPIRY:-1h}
      # Service URLs (internal)
      - DOCUMENT_SERVICE_URL=http://document-service:4001
      - AI_SERVICE_URL=http://ai-service:4002
      - INTERNAL_SERVICE_TOKEN=${INTERNAL_SERVICE_TOKEN}
      - DOCUMENT_SERVICE_TIMEOUT=${DOCUMENT_SERVICE_TIMEOUT:-30000}
      - AI_SERVICE_TIMEOUT=${AI_SERVICE_TIMEOUT:-10000}
      # SharePoint (optional)
      - SHAREPOINT_SITE_ID=${SHAREPOINT_SITE_ID:-}
      - SHAREPOINT_DRIVE_ID=${SHAREPOINT_DRIVE_ID:-}
      # Confluence (optional)
      - CONFLUENCE_BASE_URL=${CONFLUENCE_BASE_URL:-}
      - CONFLUENCE_USERNAME=${CONFLUENCE_USERNAME:-}
      - CONFLUENCE_API_TOKEN=${CONFLUENCE_API_TOKEN:-}
      # Azure app-only auth (optional, falls back to AUTH_* if not set)
      - AZURE_APP_CLIENT_ID=${AZURE_APP_CLIENT_ID:-}
      - AZURE_APP_CLIENT_SECRET=${AZURE_APP_CLIENT_SECRET:-}
      - AZURE_TENANT_ID=${AZURE_TENANT_ID:-}
      # LLM configuration (legacy, for backward compatibility)
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_BASE_URL=http://ollama:11434
      - LLM_MODEL=${LLM_MODEL:-llama2}
      - LLM_SIMILARITY_THRESHOLD=${LLM_SIMILARITY_THRESHOLD:-70}
      # Email configuration (optional)
      - EMAIL_SMTP_HOST=${EMAIL_SMTP_HOST:-}
      - EMAIL_SMTP_PORT=${EMAIL_SMTP_PORT:-587}
      - EMAIL_SMTP_USER=${EMAIL_SMTP_USER:-}
      - EMAIL_SMTP_PASS=${EMAIL_SMTP_PASS:-}
      - EMAIL_FROM=${EMAIL_FROM:-}
    env_file:
      - .env
      - ./backend/.env
    networks:
      - isms-network
    depends_on:
      postgres:
        condition: service_healthy
      document-service:
        condition: service_healthy
      ai-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:4000/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
      args:
        VITE_API_URL: ${VITE_API_URL}
        VITE_AUTH_TENANT_ID: ${VITE_AUTH_TENANT_ID}
        VITE_AUTH_CLIENT_ID: ${VITE_AUTH_CLIENT_ID}
        VITE_AUTH_REDIRECT_URI: ${VITE_AUTH_REDIRECT_URI}
        VITE_APP_VERSION: ${VITE_APP_VERSION:-1.0.0}
    container_name: isms-frontend-ec2
    restart: unless-stopped
    ports:
      - "3000:80"
    networks:
      - isms-network
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local
  ollama_data:
    driver: local
  document_cache:
    driver: local

networks:
  isms-network:
    driver: bridge

